# 故障排除指南

我们已经走了这么远，我相信你们正在享受这个充满挑战和快乐的学习旅程的每一刻。我不会说这本书在这一章之后就结束了，而是说你正在完成第一个里程碑。这一里程碑为学习和实施基于微服务设计的云计算新范式打开了大门。我想重申，集成测试是测试微服务和 API 之间交互的重要方法。在开发示例应用程序**在线表格预订系统**（**OTRS**时，我相信您遇到了很多挑战，尤其是在调试应用程序时。在这里，我们将介绍一些实践和工具，它们将帮助您对部署的应用程序、Docker 容器和主机进行故障排除。

本章涵盖以下三个主题：

*   伐木与麋鹿群
*   使用 Zipkin 和 Sleuth 对服务调用使用相关 ID
*   依赖项和版本

# 伐木与麋鹿群

您能想象在没有看到生产系统日志的情况下调试任何问题吗？因为时光倒流是很困难的。因此，我们需要日志记录。如果日志是这样设计和编码的，那么日志也会给我们关于系统的警告信号。日志记录和日志分析是解决任何问题的重要步骤，也是吞吐量、容量和监控系统运行状况的重要步骤。因此，拥有一个非常好的日志平台和策略将实现有效的调试。日志记录是软件开发初期最重要的关键组件之一。

微服务通常使用图像容器（如 Docker）进行部署，这些容器为日志提供命令，帮助您读取容器中部署的服务的日志。Docker 和 Docker Compose 提供命令，分别在容器和所有容器中对正在运行的服务的日志输出进行流式处理。请参考以下 Docker 和 Docker Compose 的`logs`命令：

**Docker logs command:** **Usage:** `docker logs [OPTIONS] <CONTAINER NAME>`  **Fetch the logs of a container:**
`**-f, --follow Follow log output**`
`**--help Print usage**`
`**--since="" Show logs since timestamp**`
`**-t, --timestamps Show timestamps**`
`**--tail="all" Number of lines to show from the end of the logs**`

**Docker Compose logs command:** `**Usage: docker-compose logs [options] [SERVICE...]**`
**Options:**
`**--no-color Produce monochrome output**`
`**-f, --follow Follow log output**`
`**-t, --timestamps Show timestamps**`
`**--tail Number of lines to show from the end of the logs for each container**
**[SERVICES...] Service representing the container - you can give multiple**`

这些命令可以帮助您查看容器中运行的微服务和其他进程的日志。如您所见，当您有更多的服务时，使用上述命令将是一项具有挑战性的任务。例如，如果您有数十个或数百个微服务，则很难跟踪每个微服务日志。类似地，您可以想象，即使没有容器，单独监视日志也是多么困难。因此，您可以假设探索和关联数十到数百个容器的日志很困难。这很费时，附加值也很小。

因此，日志聚合器和可视化工具，如麋鹿堆栈来拯救我们。它将用于集中日志记录。我们将在下一节中对此进行探讨。

# 简要概述

**Elasticsearch、Logstash、Kibana**（**麋鹿**）堆栈是一系列工具，用于执行日志聚合、分析、可视化和监控。ELK stack 提供了一个完整的日志平台，允许您分析、可视化和监控所有日志，包括所有类型的产品日志和系统日志。如果你已经知道麋鹿群，请跳到下一节。在这里，我们将简要介绍麋鹿堆栈中的每个工具：

![](assets/87defb1f-0f40-4d90-8f8d-0be85aaf64c6.png)

麋鹿概述（来源：elastic.co）

# 弹性搜索

Elasticsearch 是最流行的企业全文搜索引擎之一。它是开源软件。它是可分发的，支持多租户。单个 Elasticsearch 服务器存储多个索引（每个索引代表一个数据库），单个查询可以搜索多个索引的数据。它是一个分布式搜索引擎，支持集群。

它易于扩展，可以提供接近实时的搜索，延迟为 1 秒。它是使用 ApacheLucene 在 Java 中开发的。ApacheLucene 也是免费和开源的，它提供了 Elasticsearch 的核心，也称为信息检索软件库。

ElasticSearchAPI 本质上是广泛的，并且非常精巧。Elasticsearch 提供了一个基于 JSON 的模式，存储更少，并用 JSON 表示数据模型。ElasticSearchAPI 将 JSON 文档用于 HTTP 请求和响应。

# 伐木场

Logstash 是一个具有实时管道功能的开源数据收集引擎。简单地说，它收集、解析、处理和存储数据。由于 Logstash 具有数据管道功能，它可以帮助您处理来自各种系统的任何事件数据，例如日志。Logstash 作为代理运行，收集数据、解析数据、过滤数据，并将输出发送到指定的应用程序，如 Elasticsearch 或控制台上的简单标准输出。

它还有一个非常好的插件生态系统（图片来源于[www.elastic.co](http://www.elastic.co)：

![](assets/d8951d1d-10a5-4118-bf8d-6a6174fb9975.jpg)

伐木生态系统

# 基巴纳

Kibana 是一个开源分析和可视化 web 应用程序。它设计用于 Elasticsearch。您可以使用 Kibana 搜索、查看和交互存储在 Elasticsearch 索引中的数据。

它是一个基于浏览器的 web 应用程序，允许您执行高级数据分析，并在各种图表、表格和地图中可视化数据。此外，它是一个零配置应用程序。因此，它不需要任何额外的基础设施，也不需要在安装后进行编码。

# 麋鹿堆叠设置

通常，这些工具是单独安装的，然后配置为相互通信。这些组件的安装非常简单。从指定位置下载可安装工件，并按照安装步骤进行操作，如下一节所示。

下面提供的安装步骤是设置要运行的麋鹿堆栈所需的基本设置的一部分。由于此安装是在本地主机上完成的，因此我使用了主机 localhost。可以使用您想要的任意主机名轻松地更改它。

# 安装 Elasticsearch

要安装 Elasticsearch，我们可以使用 Elasticsearch Docker 图像：

```
docker pull docker.elastic.co/elasticsearch/elasticsearch:5.5.1 
```

我们还可以通过以下步骤安装 Elasticsearch：

1.  从[下载最新的 Elasticsearch 发行版 https://www.elastic.co/downloads/elasticsearch](https://www.elastic.co/downloads/elasticsearch) 。
2.  将其解压缩到系统中所需的位置。
3.  确保安装了最新的 Java 版本，并设置了`JAVA_HOME`环境变量。
4.  转到 Elasticsearch 主页，在基于 Unix 的系统上运行`bin/elasticsearch`，在 Windows 上运行`bin/elasticsearch.bat`。
5.  打开任意浏览器并点击`http://localhost:9200/`。成功安装后，它应为您提供类似以下内容的 JSON 对象：

```
{ 
  "name" : "Leech", 
  "cluster_name" : "elasticsearch", 
  "version" : { 
    "number" : "2.3.1", 
    "build_hash" : "bd980929010aef404e7cb0843e61d0665269fc39", 
    "build_timestamp" : "2016-04-04T12:25:05Z", 
    "build_snapshot" : false, 
    "lucene_version" : "5.5.0" 
  }, 
  "tagline" : "You Know, for Search" 
}
```

默认情况下，未安装 GUI。您可以从`bin`目录执行以下命令安装一个；确保系统已连接到 internet：

```
  plugin -install mobz/elasticsearch-head

```

6.  如果您使用的是 Elasticsearch 图像，则运行 Docker 图像（稍后，我们将使用`docker-compose`一起运行麋鹿堆栈）。
7.  现在，您可以通过 URL`http://localhost:9200/_plugin/head/`访问 GUI 界面。您可以用各自的主机名和端口号替换`localhost`和`9200`。

# 安装日志库

要安装 Logstash，我们可以使用 Logstash Docker 映像：

```
docker pull docker.elastic.co/logstash/logstash:5.5.1 
```

我们还可以通过执行以下步骤来安装 Logstash：

1.  从[下载最新的 Logstash 发行版 https://www.elastic.co/downloads/logstash](https://www.elastic.co/downloads/logstash) 。
2.  将其解压缩到系统中所需的位置。
    准备一个配置文件，如图所示。它指示 Logstash 从给定的文件读取输入，并将其传递给 Elasticsearch（请参见下面的`config`文件；Elasticsearch 由 localhost 和`9200`端口表示）。它是最简单的配置文件。要添加过滤器并了解有关 Logstash 的更多信息，您可以浏览[上提供的 Logstash 参考文档 https://www.elastic.co/guide/en/logstash/current/index.html](https://www.elastic.co/guide/en/logstash/current/index.html) ：

如您所见，OTR`service`日志和`edge-server`日志被添加为输入。同样，您也可以添加其他微服务的日志文件。

```
input { 
  ### OTRS ### 
  file { 
    path => "\logs\otrs-service.log" 
    type => "otrs-api" 
    codec => "json" 
    start_position => "beginning" 
  } 

  ### edge ### 
  file { 
    path => "/logs/edge-server.log" 
    type => "edge-server" 
    codec => "json" 
  } 
} 

output { 
  stdout { 
    codec => rubydebug 
  } 
  elasticsearch { 
    hosts => "localhost:9200" 
  } 
} 
```

3.  转到 Logstash home，在基于 Unix 的系统上运行`bin/logstash agent -f logstash.conf`，在 Windows 上运行`bin/logstash.bat agent -f logstash.conf`。这里，使用`agent`命令执行 Logstash。Logstash 代理从配置文件的输入字段中提供的源收集数据，并将输出发送到 Elasticsearch。这里，我们没有使用过滤器，因为否则它可能会在将输入数据提供给 Elasticsearch 之前处理输入数据。

类似地，您可以使用下载的 Docker 映像运行 Logstash（稍后，我们将使用`docker-compose`一起运行 ELK 堆栈）。

# 安装 Kibana

要安装 Kibana，我们可以使用 Kibana Docker 映像：

```
docker pull docker.elastic.co/kibana/kibana:5.5.1 
```

我们还可以通过执行以下步骤来安装 Kibana web 应用程序：

1.  从[下载最新的 Kibana 发行版 https://www.elastic.co/downloads/kibana](https://www.elastic.co/downloads/kibana) 。
2.  将其解压缩到系统中所需的位置。

3.  从 Kibana 主目录打开配置文件`config/kibana.yml`，将`elasticsearch.url`指向之前配置的 Elasticsearch 实例：

```
   elasticsearch.url: "http://localhost:9200"
```

4.  转到 Kibana home，在基于 Unix 的系统上运行`bin/kibana agent -f logstash.conf`，在 Windows 上运行`bin/kibana.bat agent -f logstash.conf`。
5.  如果您使用的是 Kibana Docker 映像，那么您可以运行 Docker 映像（稍后，我们将使用 Docker compose 一起运行 ELK 堆栈）。
6.  现在，您可以使用 URL`http://localhost:5601/`从浏览器访问 Kibana 应用程序。
    要了解更多关于 Kibana 的信息，请在[浏览 Kibana 参考文档 https://www.elastic.co/guide/en/kibana/current/getting-started.html](https://www.elastic.co/guide/en/kibana/current/getting-started.html) 。

当我们按照前面的步骤操作时，您可能已经注意到它需要一些努力。如果要避免手动设置，可以将其 Dockerize。如果您不想努力创建麋鹿堆栈的 Docker 容器，可以从 Docker Hub 中选择一个。在 Docker Hub 上，有许多现成的麋鹿堆叠 Docker 图像。你可以尝试不同的麋鹿容器，选择最适合你的。`willdurand/elk`是下载最多的容器，易于启动，与 Docker Compose 配合良好。

# 使用 Docker Compose 运行麋鹿堆栈

elastic.co 自己的 Docker 存储库中提供的 ELK 图像在编写本节时默认启用 XPack 包。将来，它可能是可选的。根据麋鹿图像中 XPack 的可用性，您可以修改 docker compose 文件`docker-compose-elk.yml`：

```
version: '2' 

services: 
  elasticsearch: 
    image: docker.elastic.co/elasticsearch/elasticsearch:5.5.1 
    ports: 
      - "9200:9200" 
      - "9300:9300" 
    environment: 
      ES_JAVA_OPTS: "-Xmx256m -Xms256m" 
      xpack.security.enabled: "false" 
      xpack.monitoring.enabled: "false" 
      # below is required for running in dev mode. For prod mode remove them and vm_max_map_count kernel setting needs to be set to at least 262144 
      http.host: "0.0.0.0" 
      transport.host: "127.0.0.1" 
    networks: 
      - elk 

  logstash: 
    image: docker.elastic.co/logstash/logstash:5.5.1 
    #volumes: 
    #  - ~/pipeline:/usr/share/logstash/pipeline 
    #  windows manually copy to docker cp pipleline/logstash.conf 305321857e9f:/usr/share/logstash/pipeline. restart container after that 
    ports: 
      - "5001:5001" 
    environment: 
      LS_JAVA_OPTS: "-Xmx256m -Xms256m" 
      xpack.monitoring.enabled: "false" 
      xpack.monitoring.elasticsearch.url: "http://192.168.99.100:9200" 
      command: logstash -e 'input { tcp { port => 5001 codec => "json" } } output { elasticsearch { hosts => "192.168.99.100" index => "mmj" } }' 
    networks: 
      - elk 
    depends_on: 
      - elasticsearch 

  kibana: 
    image: docker.elastic.co/kibana/kibana:5.5.1 
    ports: 
      - "5601:5601" 
    environment: 
      xpack.security.enabled: "false" 
      xpack.reporting.enabled: "false" 
      xpack.monitoring.enabled: "false" 
    networks: 
      - elk 
    depends_on: 
      - elasticsearch 

networks: 
  elk: 
    driver: bridge 

```

保存麋鹿 Docker Compose 文件后，可以使用以下命令运行麋鹿堆栈（该命令从包含 Docker Compose 文件的目录中运行）：

```
docker-compose -f docker-compose-elk.yml up -d 
```

前面命令的输出如以下屏幕截图所示：

![](assets/c32104c2-3d7a-4822-a5f1-15d7e7be0b52.png)

使用 Docker Compose 运行麋鹿堆栈

如果未使用卷，则环境管道不工作。对于 Windows 7 等通常很难配置卷的 Windows 环境，您可以在容器内复制管道配置文件并重新启动 Logstash 容器：

```
docker cp pipleline/logstash.conf <logstash container id>:/usr/share/logstash/pipeline 
```

复制管道配置文件`pipeline/logstash.conf`后，请重新启动日志存储容器：

```
input { 
  tcp { 
    port => 5001 
    codec => "json" 
  } 
} 

output { 
  elasticsearch { 
    hosts => "elasticsearch:9200" 
  } 
} 
```

# 将日志推送到麋鹿堆

我们已经完成了麋鹿堆的制作。现在，Logstash 只需要一个可以通过 Elasticsearch 索引的日志流。创建日志的 Elasticsearch 索引后，可以在 Kibana 仪表板上访问和处理日志。

要将日志推送到 Logstash，我们需要在服务代码中进行以下更改。我们需要在 OTRS 服务中添加 logback 和 logstash logback 编码器依赖项。

在`pom.xml`文件中添加以下依赖项：

```
... 
<dependency> 
    <groupId>net.logstash.logback</groupId> 
    <artifactId>logstash-logback-encoder</artifactId> 
    <version>4.6</version> 
</dependency> 
<dependency> 
    <groupId>ch.qos.logback</groupId> 
    <artifactId>logback-core</artifactId> 
    <version>1.1.9</version> 
</dependency> 
... 
```

我们还需要通过在`src/main/resources`中添加`logback.xml`来配置 logback。

`logback.xml`文件将如下所示：

```
<?xml version="1.0" encoding="UTF-8"?> 
<configuration debug="true"> 
    <appender name="stash" class="net.logstash.logback.appender.LogstashTcpSocketAppender"> 
        <destination>192.168.99.100:5001</destination> 
        <!-- encoder is required --> 
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" /> 
        <keepAliveDuration>5 minutes</keepAliveDuration> 
    </appender> 
    <appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"> 
        <encoder> 
            <pattern>%d{HH:mm:ss.SSS} [%thread, %X{X-B3-TraceId:-},%X{X-B3-SpanId:-}] %-5level %logger{36} - %msg%n</pattern> 
        </encoder> 
    </appender> 

    <property name="spring.application.name" value="nameOfService" scope="context"/> 

    <root level="INFO"> 
        <appender-ref ref="stash" /> 
        <appender-ref ref="stdout" /> 
    </root> 

    <shutdownHook class="ch.qos.logback.core.hook.DelayingShutdownHook"/> 
</configuration>
```

这里，目的地是`192.168.99.100:5001`，Logstash 所在地；您可以根据您的配置进行更改。对于编码器，使用`net.logstash.logback.encoder.LogstashEncoder`类。`spring.application.name`属性的值应设置为为其配置的服务。类似地，还添加了一个 shutdownhook，这样一旦服务停止，所有资源都应该被释放和清理。

您希望在麋鹿堆栈可用后启动服务，以便服务可以将日志推送到 Logstash。

一旦麋鹿堆栈和服务启动，您可以检查麋鹿堆栈以查看日志。您希望在启动 ELK 堆栈后等待几分钟，然后访问以下 URL（根据您的配置替换 IP）。

要检查 Elasticsearch 是否已启动，请访问以下 URL：

```
http://192.168.99.100:9200/  
```

要检查是否已创建索引，请访问以下 URL 之一：

```
http://192.168.99.100:9200/_cat/indices?v 
http://192.168.99.100:9200/_aliases?pretty 
```

完成 Logstash 索引后（您可能有几个服务端点来生成一些日志），访问 Kibana：

```
http://192.168.99.100:5601/ 
```

# ELK 堆栈实现技巧

以下是实施麋鹿堆栈的一些有用提示：

*   为了避免任何数据丢失和处理输入负载的突然峰值，建议在 Logstash 和 Elasticsearch 之间使用诸如 Redis 或 RabbitMQ 之类的代理。
*   如果您使用群集来防止大脑分裂问题，请使用奇数个节点进行 Elasticsearch。
*   在 Elasticsearch 中，始终为给定数据使用适当的字段类型。这将允许您执行不同的检查；例如，`int`字段类型将允许您执行`("http_status:<400")`或`("http_status:=200")`。类似地，其他字段类型也允许您执行类似的检查。

# 对服务调用使用相关 ID

当您调用任何 REST 端点时，如果出现任何问题，则很难跟踪问题及其根源，因为每次调用都是对服务器进行的，而此调用可能调用另一个，依此类推。这使得我们很难弄清楚一个特定的请求是如何转换的，以及它被称为什么。通常，由一个服务引起的问题可能会对其他服务产生多米诺骨牌效应，或者导致其他服务操作失败。跟踪非常困难，可能需要付出巨大的努力。如果它是单片的，您知道您正在朝着正确的方向看，但是微服务使您很难理解问题的来源以及您应该从哪里获得数据。

# 让我们看看如何解决这个问题

通过使用在所有调用中传递的关联 ID，它允许您跟踪每个请求并轻松跟踪路由。每个请求都有其唯一的关联 ID。因此，当我们调试任何问题时，关联 ID 是我们的起点。我们可以跟踪它，一路上，我们可以发现哪里出了问题。

correlation ID 需要一些额外的开发工作，但这项工作花得很好，因为从长远来看，它有很大帮助。当一个请求在不同的微服务之间传递时，您将能够看到所有的交互以及哪个服务有问题。

这不是新事物，也不是为微服务而发明的。此模式已被许多流行产品（如 Microsoft SharePoint）使用。

# 使用 Zipkin 和 Sleuth 进行跟踪

对于 OTRS 应用程序，我们将使用 Zipkin 和 Sleuth 进行跟踪。它提供了跟踪 ID 和范围 ID 以及一个很好的 UI 来跟踪请求。更重要的是，您可以在 Zipkin 中找到每个请求所花费的时间，它允许您向下搜索以找到使服务请求的时间最长的请求。

在下面的屏幕截图中，您可以看到餐厅的`findById`API 调用所花费的时间以及同一请求的跟踪 ID。它还显示了 span ID：

![](assets/b2422251-7e3e-4319-947a-3d747347f8b8.png)

餐厅`findById`API 调用的总时间和跟踪 ID

我们将遵循以下步骤在 OTRS 服务中配置 Zipkin 和 Sleuth。

您只需添加 Sleuth 和 Sleuth Zipkin 依赖项即可启用跟踪和请求跟踪：

```
<dependency> 
    <groupId>org.springframework.cloud</groupId> 
    <artifactId>spring-cloud-starter-sleuth</artifactId> 
</dependency> 
<dependency> 
    <groupId>org.springframework.cloud</groupId> 
    <artifactId>spring-cloud-sleuth-zipkin</artifactId> 
</dependency> 
```

访问 Zipkin 仪表板，找出不同请求所花费的时间。如果更改了默认端口，请更换端口。在使用 Zipkin 之前，请确保服务已启动：

```
http://<zipkin host name>:9411/zipkin/ 
```

现在，如果 ELK 堆栈已配置并启动，则可以使用此跟踪 ID 在 Kibana 中查找适当的日志，如下面的屏幕截图所示。Kibana 中有 X-B3-TraceId 字段，用于根据跟踪 ID 过滤日志：

![](assets/04a4d229-71fa-4d6d-97b5-0289e3e650cd.png)

Kibana 仪表板-基于请求跟踪 ID 进行搜索

# 依赖项和版本

我们在产品开发中面临的两个常见问题是循环依赖关系和 API 版本。我们将从基于微服务的体系结构的角度讨论它们。

# 循环依赖及其影响

通常，单片体系结构具有典型的层模型，而微服务具有图形模型。因此，微服务可能具有循环依赖性。

因此，有必要对微服务关系进行依赖性检查。

让我们看看以下两种情况：

*   如果您的微服务之间存在一个依赖循环，那么当某个事务可能陷入循环时，您很容易出现分布式堆栈溢出错误。例如，当一个人正在预订餐厅的桌子时。在这种情况下，餐厅需要了解该人（`findBookedUser`），该人需要在给定的时间（`findBookedRestaurant`了解该餐厅。如果设计得不好，这些服务可能会在循环中相互调用。结果可能是 JVM 生成的堆栈溢出。
*   如果两个服务共享一个依赖项，并且您以可能影响它们的方式更新了另一个服务的 API，那么您需要同时更新这三个服务。这会带来一些问题，例如，您应该首先更新哪一个？此外，如何使这成为一个安全的过渡？

# 在设计系统时分析依赖关系

因此，在设计微服务时，重要的是在内部不同服务之间建立适当的关系，以避免任何循环依赖。
这是一个设计问题，必须加以解决，即使它需要重构代码。

# 维护不同版本

当您有更多的服务时，这意味着每个服务都有不同的发布周期，这通过引入不同版本的服务而增加了复杂性，因为相同的 REST 服务将有不同的版本。当一个问题的解决方案出现在一个版本中并返回到一个更新的版本中时，重新生成该问题的解决方案将被证明是非常困难的。

# 让我们进一步探索

API 的版本控制很重要，因为随着时间的推移，API 会发生变化。您的知识和经验会随着时间的推移而提高，这会导致 API 的变化。更改 API 可能会破坏现有的客户端集成。

因此，有多种方法来管理 API 版本。其中之一是使用我们在本书中使用的路径中的版本；有些还使用 HTTP 头。HTTP 头可以是自定义请求头，也可以使用`Accept Header`表示调用 API 的版本。有关如何使用 HTTP 头处理版本的更多信息，请参阅 Bhakti Mehta 的*RESTful Java 模式和最佳实践*，Packt Publishing:[https://www.packtpub.com/application-development/restful-java-patterns-and-best-practices](https://www.packtpub.com/application-development/restful-java-patterns-and-best-practices) 。

在解决任何问题时，实现微服务以在日志中生成版本号是非常重要的。此外，理想情况下，您应该避免任何 microservice 版本过多的情况。

# 工具书类

以下链接将提供更多信息：

*   弹性搜索：[https://www.elastic.co/products/elasticsearch](https://www.elastic.co/products/elasticsearch)
*   日志存储：[https://www.elastic.co/products/logstash](https://www.elastic.co/products/logstash)
*   基巴纳：[https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana)
*   `willdurand/elk`：麋鹿码头工人图片
*   *掌握弹性搜索-第二版**版*[https://www.packtpub.com/web-development/mastering-elasticsearch-second-edition](https://www.packtpub.com/web-development/mastering-elasticsearch-second-edition)

# 总结

在本章中，我们探讨了麋鹿堆栈的概述和安装。在 ELK 堆栈中，Elasticsearch 用于存储来自 Kibana 的日志和服务查询。Logstash 是一个代理，它在您希望从中收集日志的每台服务器上运行。Logstash 读取日志，过滤/转换日志，并将其提供给 Elasticsearch。Kibana 从 Elasticsearch 读取/查询数据，并以表格或图形可视化的形式显示。

我们还了解在调试问题时拥有相关 ID 的实用性。在本章的最后，我们还发现了一些微服务设计的缺点。在这本书中，要涵盖所有与微服务相关的主题是一项具有挑战性的任务，因此，我尝试在精确的章节中包含尽可能多的相关信息，并附上参考资料，这使您能够进行更多的探索。现在，我想让你们开始在你们的工作场所或个人项目中实施我们在本章学到的概念。这不仅可以让您获得实际操作经验，还可以让您掌握微服务。此外，您还可以参加当地的会议。