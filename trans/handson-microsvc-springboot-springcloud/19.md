# 使用 EFK 堆栈进行集中式日志记录

在本章中，我们将学习如何从 microservice 实例收集和存储日志记录，以及如何搜索和分析日志记录。正如我们在[第 1 章](01.html)、*微服务简介*（参考*集中式日志分析*一节）中提到的，当每个微服务实例将日志记录写入其本地文件系统时，很难对微服务的系统场景中发生的情况进行概述。我们需要一个组件，它可以从微服务的本地文件系统收集日志记录，并将它们存储在一个中央数据库中，以便进行分析、搜索和可视化。一个流行的基于开源的解决方案基于以下工具：

*   **Elasticsearch***一个分布式数据库，具有强大的搜索和分析大型数据集的能力*
**   **Fluentd**是一款数据采集器，可以从各种来源收集日志记录，对收集到的信息进行过滤和转换，最后发送给各种消费者，例如 Elasticsearch*   **Kibana**，Elasticsearch 的图形前端，可用于可视化搜索结果并对收集的日志记录进行分析*

 *这些工具统称为**EFK 堆栈**，以每个工具的首字母命名。

本章将介绍以下主题：

*   配置 Fluentd
*   在 Kubernetes 上部署 EFK 堆栈以供开发和测试使用
*   通过以下方式尝试 EFK 堆栈：
    *   分析收集的日志记录
    *   从微服务中发现日志记录并查找相关日志记录
    *   执行根本原因分析

# 技术要求

本书中描述的所有命令都是使用 macOS Mojave 在 MacBook Pro 上运行的，但修改起来应该很简单，以便可以在其他平台（如 Linux 或 Windows）上运行。

本章中无需安装新工具。

本章的源代码可以在本书的 GitHub 存储库中找到：[https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter19](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter19) 。

为了能够运行本书中描述的命令，您需要将源代码下载到一个文件夹，并设置一个环境变量`$BOOK_HOME`，该变量指向该文件夹。一些示例命令如下所示：

```
export BOOK_HOME=~/Documents/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud
git clone https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud $BOOK_HOME
cd $BOOK_HOME/Chapter19
```

本章中的所有源代码示例均来自`$BOOK_HOME/Chapter19`中的源代码，并已使用 Kubernetes 1.15 进行了测试。

如果您想查看我们在本章中对源代码所做的更改，即我们所做的更改，以便我们可以使用 EFK 堆栈进行集中日志分析，您可以将其与[第 18 章](18.html)*的源代码进行比较，*使用服务网格来提高可观察性和管理*。您可以使用您最喜欢的`diff`工具比较两个文件夹`$BOOK_HOME/Chapter18`和`$BOOK_HOME/Chapter19`。*

# 配置 Fluentd

在本节中，我们将学习如何配置 Fluentd 的基础知识。在此之前，让我们先了解一下 Fluentd 的背景知识，以及它在高层的工作原理。

# 介绍 Fluentd

历史上，处理日志记录最流行的开源堆栈之一是 Elastic（[的 ELK 堆栈 https://www.elastic.co](https://www.elastic.co) ），基于 Elasticsearch、Logstash（用于日志收集和转换）和 Kibana。由于 Logstash 在 Java 虚拟机上运行，因此需要相对较大的内存量。多年来，已经开发了许多开源替代方案，它们需要的内存比 Logstash 少得多，其中之一就是 Fluentd（[https://www.fluentd.org](https://www.fluentd.org) ）。

Fluentd 是由云计算的基础计算的，T1（T1）。https://www.cncf.io ），即管理 Kubernetes 项目的同一组织。因此，Fluentd 已成为在 Kubernetes 中运行的基于开源的日志收集器的自然选择。它与 Elastic 和 Kibana 一起构成 EFK 堆栈。

Fluentd 是用 C 和 Ruby 混合编写的，在性能关键的部分使用 C，在灵活性更重要的地方使用 Ruby，例如，允许使用 Ruby 的`gem install`命令简单地安装第三方插件。

日志记录在 Fluentd 中作为事件处理，包括以下信息：

*   描述日志记录创建时间的`time`字段
*   Fluentd 的路由引擎使用一个`tag`字段来确定日志记录的处理方式，该字段标识标签的日志记录类型
*   一个包含实际日志信息的**记录**，它存储为 JSON 对象

Fluentd 配置文件用于告诉 Fluentd 如何收集、处理日志记录，并最终将其发送到各种目标，如 Elasticsearch。配置文件由以下类型的核心元素组成：

*   `<source>`：源元素描述 Fluentd 收集日志记录的位置。例如，跟踪 Docker 容器写入的日志文件。源元素通常标记日志记录，描述日志记录的类型。例如，它可以用来标记日志记录，以表明它们来自运行在 Kubernetes 中的容器。
*   `<filter>`：过滤元素用于处理日志记录，例如，过滤元素可以解析来自基于 Spring Boot 的微服务的日志记录，并将日志消息的感兴趣部分提取到日志记录中的单独字段中。将信息提取到日志记录中的单独字段中，可以通过 Elasticsearch 搜索信息。过滤器元素根据日志记录的标记选择要处理的日志记录
*   `<match>`：输出元素用于执行两个主要任务：
    *   将处理后的日志记录发送到 Elasticsearch 等目标。
    *   路由是决定如何处理日志记录。路由规则可以重写标记并将日志记录重新提交到 Fluentd 路由引擎中进行进一步处理。路由规则表示为嵌入在`<match>`元素中的`<rule>`元素。输出元素决定要处理哪些日志记录，方法与过滤器相同：基于日志记录的标记

Fluentd 附带了许多内置和外部第三方插件，供源、过滤器和输出元素使用。当我们在下一节中浏览配置文件时，我们将看到其中一些功能正在发挥作用。有关可用插件的更多信息，请参阅 Fluentd 的文档，该文档位于[https://docs.fluentd.org](https://docs.fluentd.org) 。

通过对 Fluentd 的介绍，我们已经准备好了解如何配置 Fluentd 来处理来自微服务的日志记录。

# 配置 Fluentd

Fluentd 的配置基于 GitHub 上 Fluentd 项目`fluentd-kubernetes-daemonset`的配置文件。该项目包含 Fluentd 配置文件，用于了解如何从 Kubernetes 中运行的容器中收集日志记录，以及如何在处理完日志记录后将其发送到 Elasticsearch。我们可以重用这个配置而不做任何更改，它将在很大程度上简化我们自己的配置。Fluentd 配置文件可在[找到 https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.4/debian-elasticsearch/conf](https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.4/debian-elasticsearch/conf)

提供此功能的配置文件为`kubernetes.conf`和`fluent.conf`。`kubernetes.conf`配置文件包含以下信息：

*   跟踪容器日志文件和 Kubernetes 之外运行的进程的日志文件的源元素，例如，`kubelet`和 Docker 守护进程。源元素还使用日志文件的全名标记 Kubernetes 的日志记录，其中`/`替换为`.`并以`kubernetes`为前缀。由于标记基于完整的文件名，因此名称包含名称空间、pod 和容器的名称以及其他内容。因此，标记对于通过匹配标记来查找感兴趣的日志记录非常有用。例如，来自`product-composite`微服务的标签可能类似于`kubernetes.var.log.containers.product-composite-7...s_hands-on_comp-e...b.log`，而同一 pod 中对应`istio-proxy`的标签可能类似于`kubernetes.var.log.containers.product-composite-7...s_hands-on_istio-proxy-1...3.log`。
*   一个过滤器元素，用于丰富来自 Kubernetes 内部运行的容器的日志记录，以及 Kubernetes 特定的字段，这些字段包含容器的名称及其运行的命名空间等信息。

主配置文件`fluent.conf`包含以下信息：

*   其他配置文件的`@include`语句，例如前面描述的`kubernetes.conf`文件。它还包括放置在特定文件夹中的自定义配置文件，使我们可以非常轻松地重用这些配置文件，而无需进行任何更改，并提供我们自己的配置文件，该文件只处理与我们自己的日志记录相关的处理。我们只需要将自己的配置文件放在`fluent.conf`文件指定的文件夹中。
*   向 Elasticsearch 发送日志记录的输出元素。

正如我们在*部署 Fluentd*一节中所述，这两个配置文件将打包到我们将为 Fluentd 构建的 Docker 映像中

我们自己的配置文件中还有以下内容：

*   从我们的微服务中检测并解析 Spring 引导格式的日志记录。
*   处理多行堆栈跟踪。例如，堆栈跟踪使用多行写入日志文件。这使得 Fluentd 很难将堆栈跟踪作为单个日志记录处理
*   将`istio-proxy`侧车中的日志记录与运行在同一 pod 中的微服务创建的日志记录分离。`istio-proxy`创建的日志记录与我们基于 Spring Boot 的微服务创建的日志模式不同。因此，必须单独处理它们，以便 Fluentd 不会试图将它们解析为 Spring 引导格式的日志记录。

为了实现这一点，配置在很大程度上基于使用`rewrite_tag_flter`插件。此插件可用于路由日志记录，其原理是更改标记的名称，然后将日志记录重新提交给 Fluentd 路由引擎

此过程由以下 UML 活动图总结：

![](Images/4aa9c779-4a07-422d-af6c-00539062d30a.png)

在高层，配置文件的设计如下所示：

*   来自 Istio 的所有日志记录的标记，包括`istio-proxy`，都以`istio`作为前缀，以便它们可以与基于 Spring Boot 的日志记录分开。
*   来自`hands-on`命名空间的所有日志记录的标记（来自`istio-proxy`的日志记录除外）都以`spring-boot`作为前缀。
*   检查 Spring Boot 的日志记录是否存在多行堆栈跟踪。如果日志记录是多行堆栈跟踪的一部分，则由第三方`detect-exceptions`插件处理以重新创建堆栈跟踪。否则，将使用正则表达式对其进行解析，以提取感兴趣的信息。有关此第三方插件的详细信息，请参见*部署 Fluentd*部分。

`fluentd-hands-on.conf`配置文件紧跟此活动图。配置文件放在 Kubernetes 配置映射中（请参见`kubernetes/efk/fluentd-hands-on-configmap.yml`），让我们一步一步地看一下，如下所示：

1.  首先是配置映射的定义和配置文件的文件名`fluentd-hands-on.conf`。情况如下：

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-hands-on-config
  namespace: kube-system
data:
  fluentd-hands-on.conf: |
```

从前面的源代码中，我们了解到，`data`元素将包含 Fluentd 的配置。它以文件名开始，并使用竖线`|`标记 Fluentd 的嵌入式配置文件的开头。

2.  第一个`<match>`元素匹配 Istio 中的日志记录，即前缀为`kubernetes`并包含`istio`作为其名称空间或容器名称的一部分的标记。看起来是这样的：

```
    <match kubernetes.**istio**>
      @type rewrite_tag_filter
      <rule>
        key log
        pattern ^(.*)$
        tag istio.${tag}
      </rule>
    </match>
```

让我们更详细地解释前面的源代码：

3.  第二个`<match>`元素匹配`hands-on`命名空间中的所有日志记录，即我们的微服务发出的日志记录。看起来是这样的：

```
    <match kubernetes.**hands-on**>
      @type rewrite_tag_filter
      <rule>
        key log
        pattern ^(.*)$
        tag spring-boot.${tag}
      </rule>
    </match>
```

从前面的源代码中，我们可以看到：

4.  第三个`<match>`元素匹配`spring-boot`日志记录，并确定它们是普通 Spring 引导日志记录还是多行堆栈跟踪的一部分。如下所示：

```
    <match spring-boot.**>
      @type rewrite_tag_filter
      <rule>
        key log
        pattern /^\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}\.\d{3}.*/
        tag parse.${tag}
      </rule>
      <rule>
        key log
        pattern /^.*/
        tag check.exception.${tag}
      </rule>
    </match>
```

如前面的源代码所示，这是通过使用两个`<rule>`元素确定的：

5.  在第四个`<match>`元素中，所选日志记录有一个以`check.exception.spring-boot`开头的标记，即作为多行堆栈跟踪一部分的日志记录。看起来是这样的：

```
    <match check.exception.spring-boot.**>
      @type detect_exceptions
      languages java
      remove_tag_prefix check
      message log
      multiline_flush_interval 5
    </match>
```

`detect_exceptions`插件的源代码如下：

6.  最后，配置文件由一个过滤器元素组成，该过滤器元素使用正则表达式解析 Spring 引导日志消息，提取感兴趣的信息。看起来是这样的：

```
    <filter parse.spring-boot.**>
      @type parser
      key_name log
      time_key time
      time_format %Y-%m-%d %H:%M:%S.%N
      reserve_data true
      format /^(?<time>\d{4}-\d{2}-
      \d{2}\s\d{2}:\d{2}:\d{2}\.\d{3})\s+
      (?<spring.level>[^\s]+)\s+
      (\[(?<spring.service>[^,]*),(?<spring.trace>[^,]*),(?
      <spring.span>[^,]*),[^\]]*\])\s+
      (?<spring.pid>\d+)\s+---\s+\[\s*(?<spring.thread>[^\]]+)\]\s+
      (?<spring.class>[^\s]+)\s*:\s+
      (?<log>.*)$/
    </filter>
```

让我们更详细地解释前面的源代码：

基于 Spring 引导的微服务的名称是使用`spring.application.name`属性指定的。此属性已添加到配置存储库中`config-repo`文件夹中的每个特定于 microservice 的属性文件中。

至少可以说，正确使用正则表达式是一项挑战。谢天谢地，有几个网站可以提供帮助。当谈到将正则表达式与 Fluentd 结合使用时，我建议使用以下站点：[https://fluentular.herokuapp.com/](https://fluentular.herokuapp.com/) 。

现在，您已经了解了 Fluentd 的工作原理和配置文件的构造方式，我们准备部署 EKF 堆栈。

# 在 Kubernetes 上部署 EFK 堆栈

在 Kubernetes 上部署 EFK 堆栈的方式与我们部署自己的微服务的方式相同：使用 Kubernetes 定义文件来定义部署、服务和配置映射等对象。

EFK 堆栈的部署分为两部分：

*   我们部署 Elasticsearch 和 Kibana 的一部分
*   我们部署 Fluentd 的一部分

但首先，我们需要构建和部署我们自己的微服务。

# 构建和部署我们的微服务

使用`test-em-all.bash`测试脚本构建、部署和验证部署的方式与[第 18 章](18.html)中的方式相同*在*运行创建服务网格的命令*部分中使用服务网格来提高可观察性和管理*中的方式相同。运行以下命令以开始：

1.  首先，使用以下命令从源代码构建 Docker 映像：

```
cd $BOOK_HOME/Chapter19
eval $(minikube docker-env)
./gradlew build && docker-compose build
```

2.  重新创建名称空间`hands-on`，并将其设置为默认名称空间：

```
kubectl delete namespace hands-on
kubectl create namespace hands-on
kubectl config set-context $(kubectl config current-context) --namespace=hands-on 
```

3.  通过使用以下命令运行`deploy-dev-env.bash`脚本来执行部署：

```
./kubernetes/scripts/deploy-dev-env.bash
```

4.  启动 Minikube 隧道，如果它还没有运行（请参见[第 18 章](18.html)、*使用服务网格来提高可观察性和管理*、*设置访问 Istio 服务*部分，如果需要，进行重述）：

```
minikube tunnel
```

请记住，此命令要求您的用户具有`sudo`权限，并且您在启动和关闭期间输入密码。命令要求输入密码需要几秒钟的时间，因此很容易出错！

5.  使用以下命令运行正常测试以验证部署：

```
./test-em-all.bash
```

预期输出与我们在前面章节中看到的类似：

![](Images/042de643-01de-4776-8b29-ab05be9fe519.png)

6.  您还可以通过运行以下命令手动试用 API：

```
ACCESS_TOKEN=$(curl -k https://writer:secret@minikube.me/oauth/token -d grant_type=password -d username=magnus -d password=password -s | jq .access_token -r)

curl -ks https://minikube.me/product-composite/2 -H "Authorization: Bearer $ACCESS_TOKEN" | jq .productId
```

在响应中需要请求的产品 ID`2`。

随着微服务的部署，我们可以继续部署 Elasticsearch 和 Kibana！

# 部署 Elasticsearch 和 Kibana

我们将把 Elasticsearch 和 Kibana 部署到它自己的名称空间`logging`。Elasticsearch 和 Kibana 都将使用 Kubernetes 部署对象部署用于开发和测试。这将通过一个 pod 和一个 Kubernetes 节点端口服务完成。这些服务将在 Kubernetes 集群内部公开 Elasticsearch 和 Kibana 的标准端口，即 Elasticserach 的端口`9200`和 Kibana 的端口`5601`。感谢`minikube tunnel`命令，我们将能够使用以下 URL 在本地访问这些服务：

*   `elasticsearch.logging.svc.cluster.local:9200`对于弹性体
*   `kibana.logging.svc.cluster.local:5601`基巴纳

有关在 Kubernetes 上的生产环境中的推荐部署，请参见[https://www.elastic.co/elasticsearch-kubernetes](https://www.elastic.co/elasticsearch-kubernetes)

我们将使用编写本章时可用的版本：

*   Elasticsearch 7.3.0 版
*   Kibana 7.3.0 版

在执行部署之前，让我们先看看定义文件中最有趣的部分。

# 定义文件的演练

Elasticsearch 的定义文件`kubernetes/efk/elasticsearch.yml`包含一个标准的 Kubernetes 部署和服务对象，我们之前已经多次看到过它，例如在[第 15 章](15.html)中的*Kubernetes 简介*中的*尝试一个示例部署*部分。如前所述，定义文件最有趣的部分如下：

```
apiVersion: extensions/v1beta1
kind: Deployment
...
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.3.0
        resources:
          limits:
            cpu: 500m
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 2Gi
```

让我们详细解释前面的源代码：

*   我们使用的是 Elastic 公司的官方 Docker 镜像，该镜像可在`docker.elastic.co`上获得，并带有一个只包含开源组件的包。这是通过在 Docker 图像的名称上使用`-oss`后缀`elasticsearch-oss`来确保的。版本设置为`7.3.0`。
*   允许 Elasticsearch 容器分配相对较大的内存—2 GB，以便能够以良好的性能执行查询。内存越多，性能越好。

Kibana 的定义文件`kubernetes/efk/kibana.yml`还包含一个标准的 Kubernetes 部署和服务对象。定义文件中最有趣的部分如下：

```
apiVersion: extensions/v1beta1
kind: Deployment
...
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana-oss:7.3.0
        env:
        - name: ELASTICSEARCH_URL
          value: http://elasticsearch:9200
```

让我们详细解释前面的源代码：

*   对于 Kibana，我们还使用了 Elastic 提供的官方 Docker 镜像，该镜像可在`docker.elastic.co`上找到，以及一个只包含开源组件的包`kibana-oss`，版本设置为`7.3.0`。
*   为了将 Kibana 与 Elasticsearch pod 连接，定义了一个环境变量`ELASTICSEARCH_URL`，用于指定 Elasticsearch 服务`http://elasticsearch:9200`的地址。

有了这些见解，我们已经准备好部署 Elasticsearch 和 Kibana。

# 运行 deploy 命令

通过执行以下步骤部署 Elasticsearch 和 Kibana：

1.  使用以下命令为 Elasticsearch 和 Kibana 创建名称空间：

```
kubectl create namespace logging
```

2.  要使部署步骤运行得更快，请使用以下命令预取 Elasticsearch 和 Kibana 的 Docker 映像：

```
eval $(minikube docker-env)
docker pull docker.elastic.co/elasticsearch/elasticsearch-oss:7.3.0
docker pull docker.elastic.co/kibana/kibana-oss:7.3.0
```

3.  部署 Elasticsearch 并使用以下命令等待其 pod 就绪：

```
kubectl apply -f kubernetes/efk/elasticsearch.yml -n logging
kubectl wait --timeout=120s --for=condition=Ready pod -n logging --all 
```

4.  使用以下命令验证 Elasticsearch 是否已启动并正在运行：

```
curl http://elasticsearch.logging.svc.cluster.local:9200 -s | jq -r .tagline
```

期待`You Know, for Search`作为回应。

根据您的硬件，您可能需要等待一两分钟，Elasticsearch 才会响应此消息。

5.  部署 Kibana 并使用以下命令等待其 pod 准备就绪：

```
kubectl apply -f kubernetes/efk/kibana.yml -n logging
kubectl wait --timeout=120s --for=condition=Ready pod -n logging --all
```

6.  使用以下命令验证 Kibana 是否已启动并运行：

```
curl -o /dev/null -s -L -w "%{http_code}\n" http://kibana.logging.svc.cluster.local:5601
```

期待`200`作为回应。

通过部署 Elasticsearch 和 Kibana，我们可以开始部署 Fluentd。

# 部署 Fluentd

与部署 Elasticsearch 和 Kibana 相比，部署 Fluentd 要复杂一些。为了部署 Fluentd，我们将使用 Docker Hub 上的 Fluentd 项目发布的 Docker 映像，`fluent/fluentd-kubernetes-daemonset`，并从 GitHub 上的 Fluentd 项目中抽取 Kubernetes 定义文件样本，`fluentd-kubernetes-daemonset`。位于[https://github.com/fluent/fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset) 。正如项目名称所暗示的，Fluentd 将作为守护程序集部署，在 Kubernetes 集群中每个节点运行一个 pod。每个 Fluentd pod 负责收集与 pod 在同一节点上运行的进程和容器的日志输出。因为我们使用的是 Minikube，也就是单节点集群，所以我们只有一个 Fluentd pod

为了处理包含异常堆栈跟踪的多行日志记录，我们将使用 Google 提供的第三方 Fluentd 插件`fluent-plugin-detect-exceptions`，该插件位于[https://github.com/GoogleCloudPlatform/fluent-plugin-detect-exceptions](https://github.com/GoogleCloudPlatform/fluent-plugin-detect-exceptions) 。为了能够使用此插件，我们将在`fluent-plugin-detect-exceptions`中创建我们自己的 Docker 映像插件将被安装。Fluentd 的 Docker 图像`fluentd-kubernetes-daemonset`将用作基础图像。

我们将使用编写本章时可用的版本：

*   Fluentd 版本 1.4.2
*   fluent 插件检测异常版本 0.0.12

在执行部署之前，让我们先看看定义文件中最有趣的部分。

# 从微服务中发现日志记录

在本节中，我们将学习如何利用集中式日志记录的主要功能之一，即从我们的微服务中查找日志记录。我们还将学习如何使用日志记录中的跟踪 ID 从属于同一进程的其他微服务中查找日志记录，例如，对 API 的请求。

让我们从创建一些日志记录开始，我们可以在 Kibana 的帮助下查找这些日志记录。我们将使用 API 创建具有唯一产品 ID 的产品，然后检索有关该产品的信息。之后，我们可以尝试查找在检索产品信息时创建的日志记录。

微服务中日志记录的创建比前一章有所更新，因此产品组合和三个核心微服务`product`、`recommendation`和`review`在开始处理 get 请求时都会写入日志记录，并将日志级别设置为`INFO`。让我们回顾一下添加到每个微服务中的源代码：

*   产品组合微服务日志创建：

```
LOG.info("Will get composite product info for product.id={}", productId);
```

*   产品微服务日志创建：

```
LOG.info("Will get product info for id={}", productId);
```

*   建议创建微服务日志：

```
LOG.info("Will get recommendations for product with id={}", productId)
```

*   查看微服务日志创建：

```
LOG.info("Will get reviews for product with id={}", productId);
```

有关更多详细信息，请参阅`microservices`文件夹中的源代码。

执行以下步骤，使用 API 创建日志记录，然后使用 Kibana 查找日志记录：

1.  使用以下命令获取访问令牌：

```
ACCESS_TOKEN=$(curl -k https://writer:secret@minikube.me/oauth/token -d grant_type=password -d username=magnus -d password=password -s | jq .access_token -r)
```

2.  如本节导言中所述，我们将首先创建一个具有唯一产品 ID 的产品。通过执行以下命令为`"productId" :1234`创建一个最低限度的产品（没有建议和评论）：

```
curl -X POST -k https://minikube.me/product-composite \
 -H "Content-Type: application/json" \
 -H "Authorization: Bearer $ACCESS_TOKEN" \
 --data '{"productId":1234,"name":"product name 1234","weight":1234}'
```

3.  使用以下命令阅读产品：

```
curl -H "Authorization: Bearer $ACCESS_TOKEN" -k 'https://minikube.me/product-composite/1234'
```

预期会出现类似以下情况的响应：

![](Images/258fd470-f7ae-432b-933e-0098656e7199.png)

希望我们能通过这些 API 调用创建一些日志记录。让我们跳到基巴纳去看看吧！

4.  在 Kibana 网页上，点击左侧的`Discover`菜单。您将看到如下内容：

![](Images/75f6dd32-2743-454f-a301-007444bb2cfd.png)

在左上角，我们可以看到 Kibaba 找到了 326642 条日志记录。时间选择器显示它们来自最近 7 天。在柱状图中，我们可以看到日志记录是如何随时间分布的。下面是一个表，显示查询找到的最新日志事件。

5.  如果要更改时间间隔，可以使用时间选择器。单击其日历图标以调整时间间隔。
6.  为了更好地查看日志记录中的内容，请将日志记录中的一些字段添加到直方图下的表中。从左侧的可用字段列表中选择字段。向下滚动，直到找到该字段。将光标停留在字段上，将出现添加按钮；单击它以将字段作为列添加到表中。按顺序选择以下字段：
    1.  spring.level，日志级别
    2.  kubernetes.container\u name，容器的名称
    3.  spring.trace，用于分布式跟踪的跟踪 ID

![](Images/e42ce2ba-2d4c-4436-95d7-cde3621c572f.png)

该表现在包含有关日志记录的相关信息！

7.  要从对`GET`API 的调用中查找日志记录，我们可以要求 Kibana 查找日志字段中包含文本 product.id=1234 的日志记录。这与前面显示的产品复合微服务的日志输出相匹配。*可通过在搜索字段中输入`log:"product.id=1234"`并点击更新按钮（此按钮也可标记为刷新）来完成。期望找到一条日志记录：*

 *![](Images/c5370730-05a8-4dc0-a414-3020057d3bb6.png)

8.  验证时间戳是否从调用`GET`API 时开始，并验证创建日志记录的容器的名称是否为 comp，即验证日志记录是否由 product composite microservice 发送。
9.  现在，我们想查看其他微服务的相关日志记录，这些微服务参与了返回 productId 为 1234 的产品信息的过程，也就是说，查找与我们找到的日志记录具有相同跟踪 ID 的日志记录。为此，将光标放在日志记录的`spring.trace`字段上。两个小放大镜将显示在视场右侧，一个带有`+`符号，另一个带有`-`符号。点击带有`+`符号的放大镜以过滤跟踪 ID。

10.  清除搜索字段，以便唯一的搜索条件是跟踪字段的过滤器。然后，单击 Update 按钮查看结果。预期会出现类似以下情况的响应：

![](Images/909125b4-7868-4ed9-b33c-3a5197408304.png)

我们可以看到许多详细的调试和跟踪消息，这些消息使视图变得混乱；让我们摆脱他们！

11.  将光标放在跟踪值上，然后单击带有-符号的放大镜，以过滤出日志级别设置为跟踪的日志记录。
12.  对调试日志记录重复上述步骤。
13.  我们现在应该能够看到四个预期的日志记录，其中一个记录用于查找产品 ID 为 1234 的产品的产品信息时涉及的每个微服务：

![](Images/437104c3-c1c1-463a-a9d9-9fe2e57f6461.png)

另外，请注意，应用的过滤器包括跟踪 ID，但排除了日志级别设置为 DEBUG 或 trace 的日志记录。

现在我们知道了如何找到预期的日志记录，我们准备好进行下一步。这将学习如何查找意外日志记录，即错误消息，以及如何执行根本原因分析，即查找这些错误消息的原因。

# 定义文件的演练

用于构建 Docker 映像的 Docker 文件`kubernetes/efk/Dockerfile`如下所示：

```
FROM fluent/fluentd-kubernetes-daemonset:v1.4.2-debian-elasticsearch-1.1

RUN gem install fluent-plugin-detect-exceptions -v 0.0.12 \
 && gem sources --clear-all \
 && rm -rf /var/lib/apt/lists/* \
           /home/fluent/.gem/ruby/2.3.0/cache/*.gem
```

让我们详细解释前面的源代码：

*   基本图像是 Fluentd 的 Docker 图像`fluentd-kubernetes-daemonset`。`v1.4.2-debian-elasticsearch-1.1`标签指定 v1.4.2 版本应与包含内置支持的包一起使用，该包用于向 Elasticsearch 发送日志记录。基本 Docker 映像包含在*配置 Fluentd*部分中提到的 Fluentd 配置文件。
*   谷歌插件`fluent-plugin-detect-exceptions`是使用 Ruby 的软件包管理器`gem`安装的。

守护进程集的定义文件`kubernetes/efk/fluentd-ds.yml`基于`fluentd-kubernetes-daemonset`项目中的一个示例定义文件，可在[找到该文件 https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/fluentd-daemonset-elasticsearch.yaml](https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/fluentd-daemonset-elasticsearch.yaml) 。这个文件有点复杂，所以让我们分别看一下最有趣的部分：

1.  首先，这里是守护进程集的声明：

```
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
```

让我们详细解释前面的源代码：

2.  下一部分指定由守护程序集创建的 pod 的模板。最有趣的部分如下：

```
spec:
  template:
    spec:
      containers:
      - name: fluentd
        image: hands-on/fluentd:v1
        env:
          - name: FLUENT_ELASTICSEARCH_HOST
            value: "elasticsearch.logging"
          - name: FLUENT_ELASTICSEARCH_PORT
            value: "9200"
```

让我们详细解释前面的源代码：

由于 Fluentd pod 在 Elasticsearch 之外的另一个命名空间中运行，因此无法使用其短名称（即`elasticsearch`）指定主机名。相反，还必须指定 DNS 名称的名称空间部分，即`elasticsearch.logging`。也可以使用**完全限定域名**（**FQDN**），`elasticsearch.logging.svc.cluster.local`。但由于 DNS 名称的最后一部分`svc.cluster.local`由 Kubernetes 群集中的所有 DNS 名称共享，因此无需指定。

3.  最后，许多卷（即文件系统）映射到 pod 中，如下所示：

```
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: journal
          mountPath: /var/log/journal
          readOnly: true
        - name: fluentd-extra-config
          mountPath: /fluentd/etc/conf.d
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: journal
        hostPath:
          path: /run/log/journal
      - name: fluentd-extra-config
        configMap:
          name: "fluentd-hands-on-config"
```

让我们详细解释前面的源代码：

有关守护程序集的定义文件的完整源代码，请参阅`kubernetes/efk/fluentd-ds.yml`文件。

现在我们已经了解了所有内容，我们已经准备好执行 Fluentd 的部署。

# 运行 deploy 命令

要部署 Fluentd，我们必须构建 Docker 映像，创建配置映射，最后部署守护程序集。运行以下命令来执行这些步骤：

1.  构建 Docker 映像，并使用以下命令将其标记为`hands-on/fluentd:v1`：

```
eval $(minikube docker-env)
docker build -f kubernetes/efk/Dockerfile -t hands-on/fluentd:v1 kubernetes/efk/
```

2.  创建配置映射，部署 Fluentd 的守护程序集，并使用以下命令等待 pod 就绪：

```
kubectl apply -f kubernetes/efk/fluentd-hands-on-configmap.yml 
kubectl apply -f kubernetes/efk/fluentd-ds.yml
kubectl wait --timeout=120s --for=condition=Ready pod -l app=fluentd -n kube-system
```

3.  使用以下命令验证 Fluentd 吊舱是否正常：

```
kubectl logs -n kube-system $(kubectl get pod -l app=fluentd -n kube-system -o jsonpath={.items..metadata.name}) | grep "fluentd worker is now running worker"
```

期望得到`2019-08-16 15:11:33 +0000 [info]: #0 fluentd worker is now running worker=0`的响应。

4.  Fluentd 将开始从 Minkube 实例中的各种进程和容器中收集大量日志记录。大约一分钟后，您可以使用以下命令询问 Elasticsearch 收集了多少日志记录：

```
curl http://elasticsearch.logging.svc.cluster.local:9200/_all/_count
```

命令在第一次执行时可能有点慢，但应返回类似于以下内容的响应：

![](Images/14a27b89-c4e5-4d29-86c2-4652b7fbe575.png)

在本例中，Elasticsearch 包含`144750`日志记录。

这就完成了 EFK 堆栈的部署。现在，是时候尝试一下了，看看所有收集的日志记录都是关于什么的！

# 尝试 EFK 堆栈

在尝试 EFK 堆栈之前，我们需要做的第一件事是初始化 Kibana，以便它知道在 Elasticsearch 中使用什么搜索索引。完成后，根据我的经验，我们将尝试以下常见任务：

1.  我们将首先分析 Fluentd 在 Elasticsearch 中收集和存储了哪些类型的日志记录。Kibana 具有非常有用的可视化功能，可用于此目的。
2.  接下来，我们将学习如何从属于同一个 API 外部请求处理的不同微服务中发现日志记录。我们将使用日志记录中的**跟踪 ID**作为相关 ID 来查找相关日志记录。
3.  第三，我们将学习如何使用 Kibana 执行**根本原因分析**，即找到错误的实际原因。

# 基巴纳酒店

在开始使用 Kibana 之前，我们必须指定在 Elasticsearch 中使用什么搜索索引，以及索引中的哪个字段保存日志记录的时间戳。

执行以下步骤初始化 Kibana：

1.  在 web 浏览器中使用`http://kibana.logging.svc.cluster.local:5601`URL 打开 Kibana 的 web UI。
2.  在欢迎页面上，欢迎来到 Kibana，单击探索我自己的按钮。

3.  单击左下角的展开按钮以查看菜单选项的名称。这些将显示在左侧。
4.  单击左侧菜单中的“发现”。您将被要求定义一个模式，Kibana 使用该模式来确定它将从中检索日志记录的 Elasticsearch 索引。
5.  进入`logstash-*`索引模式，点击下一步。
6.  在下一页中，将要求您指定包含日志记录时间戳的字段的名称。单击时间过滤器字段名称的下拉列表，并选择唯一可用的字段@timestamp。
7.  单击创建索引模式按钮。
8.  Kibana 将显示一个页面，总结所选索引中可用的字段。

出于历史原因，默认情况下，索引被命名为`logstash`，尽管它是用于日志收集的长槽索引。

Kibana 初始化后，我们就可以检查收集的日志记录了

# 分析日志记录

从 Fluentd 的部署中，我们知道它立即开始收集大量日志记录。因此，我们需要做的第一件事是了解 Fluentd 在 Elasticsearch 中收集和存储了哪些类型的日志记录。

我们将使用 Kibana 的可视化功能按照 Kubernetes 名称空间划分日志记录，然后让 Kibana 向我们展示如何按照每个名称空间中的容器类型划分日志记录。饼图是适合此类型分析的图表类型。请执行以下步骤创建饼图：

1.  在 Kibana 的 web UI 中，单击左侧菜单中的 Visualize。
2.  单击“创建新可视化”按钮。
3.  选择“饼图”作为可视化类型。
4.  选择 logstash-*作为源。
5.  在饼图上方的时间选择器（日期间隔选择器）中，设置您选择的日期间隔（在下面的屏幕截图中设置为最后 7 天）。单击其日历图标以调整时间间隔。

6.  单击 Add 以创建第一个 bucket，如下所示：
    1.  选择铲斗类型，即分割切片。
    2.  对于聚合类型，从下拉列表中选择术语。
    3.  作为字段，选择 kubernetes.namespace\u name.keyword。
    4.  对于大小，选择 10。
    5.  启用将其他值分组到单独的存储桶中。
    6.  启用“显示缺少的值”。
    7.  按下应用更改按钮（存储桶定义上方的蓝色播放图标）。应使用类似于以下内容的饼图：

![](Images/1d79e158-3af1-495b-8415-e2b769b59454.png)

我们可以看到，日志记录被划分为我们在前面章节中使用过的名称空间：`kube-system`、`istio-system`、`logging`、`cert-manager`和我们自己的`hands-on`名称空间。要查看哪些容器创建了按名称空间划分的日志记录，我们需要创建第二个 bucket。

7.  再次单击添加以创建第二个存储桶：
    1.  选择铲斗类型，即分割切片。
    2.  作为子聚合类型，从下拉列表中选择术语。
    3.  作为字段，选择 kubernetes.container\u name.keyword。
    4.  对于大小，选择 10。
    5.  启用将其他值分组到单独的存储桶中。
    6.  启用“显示缺少的值”。
    7.  再次按下“应用更改”按钮。预期会出现类似于以下内容的饼图：

![](Images/660ceb82-205e-401d-8595-5a23cc328e26.png)

在这里，我们可以从我们的微服务中找到日志记录。大多数日志记录来自`product-composite`微服务。

8.  在饼图的顶部，我们有一组标记为`missing`的日志记录，也就是说，它们既没有指定 Kubernetes 名称空间，也没有指定容器名称。这些丢失的日志记录背后是什么？这些日志记录来自 Minikube 实例中 Kubernetes 集群之外运行的进程，它们使用 Syslog 存储。可以使用 Syslog 特定字段，特别是*标识符字段来分析它们。*让我们创建第三个 bucket，它根据日志记录的 Syslog 标识符字段（如果有的话）划分日志记录
9.  再次点击`Add`创建第三个 bucket：
    1.  选择铲斗类型，即分割切片。
    2.  作为子聚合类型，从下拉列表中选择术语。
    3.  作为字段，选择 SYSLOG_IDENTIFIER.keyword。
    4.  启用将其他值分组到单独的存储桶中。
    5.  启用“显示缺少的值”。
    6.  按 Apply changes（应用更改）按钮，希望看到类似于以下内容的饼图：

![](Images/56a1d5be-61bf-49e6-87c2-a18290f65e38.png)

`missing`日志记录原来来自`kubelet`进程，该进程从 Kubernetes 的角度管理节点，而`dockerd`则来自管理所有容器的 Docker 守护进程。

现在我们已经找到了日志记录的来源，我们可以开始从我们的微服务中定位实际的日志记录。

# 执行根本原因分析

集中式日志记录最重要的特性之一是，它可以使用来自多个来源的日志记录分析错误，并在此基础上执行根本原因分析，即找到错误消息的实际原因。

在本节中，我们将模拟一个错误，并查看如何找到有关它的信息，一直到在系统环境中的一个微服务中导致错误的源代码行。为了模拟错误，我们将在*添加可编程延迟和随机错误*部分中重用[第 13 章](13.html)中介绍的故障参数*使用弹性 4J*提高弹性。我们可以使用此命令强制产品微服务引发异常。请执行以下步骤：

1.  在产品 ID 为`666`的产品上搜索产品信息时，运行以下命令在产品微服务中生成故障：

```
curl -H "Authorization: Bearer $ACCESS_TOKEN" -k https://minikube.me/product-composite/666?faultPercent=100
```

预期响应中会出现以下错误：

![](Images/8d0a558f-7fc3-4f83-bb92-320d419859ab.png)

现在，我们必须假装对这个错误的原因一无所知！否则，根本原因分析将不会非常令人兴奋，对吗？假设我们在一个支持组织中工作，并且在最终用户试图查找产品 ID 为`666`的产品信息时，我们被要求调查一些刚刚发生的问题。

2.  在我们开始分析问题之前，让我们删除 Kibana web UI 中以前的搜索过滤器，以便从头开始。对于我们在上一节中定义的每个过滤器，单击其关闭图标（x）以删除它们。删除所有筛选器后，网页的外观应类似于以下内容：

![](Images/82e6c766-b5d4-4bf8-900d-081dfff40319.png)

3.  首先，使用时间选择器选择一个时间间隔，该时间间隔包括问题发生的时间点。例如，如果知道问题发生在过去七天内，请搜索过去七天。
4.  接下来，在此时间范围内搜索日志级别设置为 ERROR 的日志记录。这可以通过单击所选字段列表中的 spring.level 字段来完成。单击此字段时，最常用的值将显示在其下方。通过单击其放大镜过滤错误值，以+号显示。Kibana 现在将显示选定时间范围内的日志记录，其日志级别设置为 ERROR，如下所示：

![](Images/70b40e75-4168-4207-90fb-e528fad127f7.png)

5.  我们可以看到许多与产品 ID`666`相关的错误消息。前四个具有相同的跟踪 ID，因此这似乎是一个用于进一步调查的感兴趣的跟踪 ID。
6.  我们还可以在前四条下面看到更多错误消息，它们似乎与相同的错误相关，但具有不同的跟踪 ID。这些都是由产品复合微服务中的重试机制引起的，也就是说，它会在放弃请求并向调用方返回错误消息之前重试请求几次。
7.  以与上一节相同的方式筛选第一条日志记录的跟踪 ID。

8.  删除错误日志级别的筛选器，以便能够查看属于此跟踪 ID 的所有记录。希望 Kibana 使用大量日志记录进行响应。查看最早的日志记录，即第一个出现的日志记录，它看起来可疑。例如，它可能具有警告或错误日志级别或奇怪的日志消息。默认的排序顺序是在顶部显示最新的日志记录，因此向下滚动到末尾并向后搜索（您也可以通过单击`Time`列标题旁边的小向上/向下箭头更改排序顺序，以首先显示最早的日志记录）。警告日志消息显示`Bad luck, and error occurred`似乎是问题的根本原因。让我们进一步调查一下：

![](Images/47ac8d1a-707a-410f-869f-d0923b4392b2.png)

9.  一旦发现可能是问题根本原因的日志记录，就非常有兴趣找到附近的堆栈跟踪，该跟踪描述了源代码**中抛出异常的位置。**不幸的是，我们用于收集多行异常的 Fluentd 插件`fluent-plugin-detect-exceptions`，无法将堆栈跟踪与使用的跟踪 ID 关联。因此，当我们对跟踪 ID 进行筛选时，堆栈跟踪不会显示在 Kibana 中。相反，我们可以使用 Kibana 中的一个功能来查找周围的日志记录，这些日志记录显示在特定日志记录的最近时间内发生的日志记录。
10.  使用日志记录左侧的箭头展开显示坏运气的日志记录。将显示有关此特定日志记录的详细信息。还有一个名为“查看周围文档”的链接；点击它查看附近的日志记录。预期会出现类似以下内容的网页：

![](Images/d533fe87-485e-4fe5-95c6-8de6c2ae04c6.png)

11.  坏运气日志记录上方的日志记录，带有错误消息“出错”的堆栈跟踪。。。看起来很有趣，产品微服务在记录了*厄运*日志记录后仅两毫秒就将其记录了下来。他们似乎有关系！该日志记录中的堆栈跟踪指向`ProductServiceImpl.java`中的第 96 行。查看源代码（参见`microservices/product-service/src/main/java/se/magnus/microservices/core/product/services/ProductServiceImpl.java`，第 96 行如下：

```
throw new RuntimeException("Something went wrong...");
```

这是错误的根本原因。我们确实事先知道这一点，但现在我们已经看到了如何导航到它。

在这种情况下，问题很容易解决：只需在对 API 的请求中省略`faultPercent`参数。在其他情况下，根本原因的解决可能更难弄清楚！

本章将结束关于使用 EFK 堆栈进行集中式日志记录的讨论。

# 总结

在本章中，我们了解了将系统环境中的微服务中的日志记录收集到公共集中式数据库中的重要性，在该数据库中可以对存储的日志记录进行分析和搜索。我们使用 EFK 堆栈，即 Elasticsearch、Fluentd 和 Kibana，来收集、处理、存储、分析和搜索日志记录。

Fluentd 不仅用于从我们的微服务收集日志记录，还用于从 Kubernetes 集群中的各种支持容器和进程收集日志记录。Elasticsearch 被用作文本搜索引擎。与 Kibana 一起，我们看到了解我们收集的日志记录类型是多么容易

我们还学习了如何使用 Kibana 执行重要任务，例如从协作的微服务中查找相关日志记录，以及如何执行根本原因分析，即查找错误消息的真正问题。最后，我们学习了如何更新 Fluentd 的配置，以及如何获得执行 Fluentd pod 所反映的更改。

能够以这种方式收集和分析日志记录是生产环境中的一项重要功能，但这些类型的活动总是在收集日志记录之后进行。另一个重要功能是能够监控微服务的当前运行状况，即收集并可视化硬件资源使用、响应时间等方面的运行时指标。我们在上一章[第 18 章](18.html)*使用服务网格提高可观察性和管理*中讨论了这个主题，在下一章[第 20 章](20.html)*监控微服务*中，我们将了解更多关于监控微服务的内容。

# 问题

1.  用户使用以下屏幕截图中显示的搜索条件在`hands-on`名称空间中搜索了过去 30 天的错误日志消息，但未找到任何消息。为什么？

![](Images/6d818708-6286-4a4c-b9f5-1ad9d67581cd.png)

2.  用户已找到感兴趣的日志记录。例如，用户如何从该微服务和其他微服务中找到来自处理外部 API 请求的相关日志记录？

![](Images/292c8785-1180-40d6-8ad2-2b7e564cc8ef.png)

3.  用户发现了一条日志记录，该记录似乎表明了最终用户报告的问题的根本原因。用户如何找到显示错误源代码发生位置的堆栈跟踪？

![](Images/6e935782-d0e3-46aa-8d97-141af6289a9c.png)

4.  为什么下面的 Fluentd 配置元素不起作用？

```
<match kubernetes.**hands-on**>
  @type rewrite_tag_filter
  <rule>
    key log
    pattern ^(.*)$
    tag spring-boot.${tag}
  </rule>
</match>
```

5.  如何确定 Elasticsearch 是否已启动并运行？

6.  突然，你失去了从网络浏览器到 Kibana 的连接。是什么导致了这个问题？**