# 理解分布式跟踪

在本章中，我们将学习如何使用分布式跟踪来更好地理解我们的微服务是如何协作的；例如，实现发送到外部 API 的请求。能够利用分布式跟踪对于能够管理协作微服务的系统环境至关重要。如[第 8 章](08.html)、*春云导论*所述，参考*春云侦探和 Zipkin 分布式追踪*章节，将使用春云侦探收集追踪信息，Zipkin 将用于上述跟踪信息的存储和可视化。

在本章中，我们将学习以下主题：

*   使用 Spring Cloud Sleuth 和 Zipkin 引入分布式跟踪
*   如何将分布式跟踪添加到源代码中
*   如何执行分布式跟踪：
    *   我们将学习如何使用 Zipkin 可视化与以下内容相关的跟踪信息：
        *   成功和不成功的 API 请求
        *   API 请求的同步和异步处理
    *   我们将使用 RabbitMQ 和 Kafka 将跟踪事件从我们的微服务发送到 Zipkin 服务器

# 技术要求

本书中描述的所有命令都是使用 macOS Mojave 在 MacBook Pro 上运行的，但修改起来应该很简单，以便可以在其他平台（如 Linux 或 Windows）上运行。

本章中无需安装新工具。

本章的源代码可在 GitHub 的[上找到 https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14) 。

为了能够按照书中所述运行命令，请将源代码下载到一个文件夹中，并设置一个指向该文件夹的环境变量`$BOOK_HOME`。一些示例命令如下所示：

```
export BOOK_HOME=~/Documents/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud
git clone https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud $BOOK_HOME
cd $BOOK_HOME/Chapter14
```

Java 源代码是为 Java8 编写的，并在 Java12 上进行了测试。本章使用 Spring Cloud 2.1.0、SR1（也称为**格林威治**版本）、Spring Boot 2.1.4 和 Spring 5.1.6，即编写本章时 Spring 组件的最新可用版本。

基本 Docker 映像`openjdk:12.0.2`用于所有 DockerFile。

本章中的所有源代码示例均来自`$BOOK_HOME/Chapter14`中的源代码，但在某些情况下，经过编辑以删除源代码中不相关的部分，如注释、导入和日志语句。

如果您想在本章中看到应用于源代码的更改，即查看使用 Spring Cloud Sleuth 和 Zipkin 添加分布式跟踪所需的时间，您可以将其与[第 13 章](13.html)、*使用 Resilience4j*提高弹性的源代码进行比较。您可以使用您最喜欢的`diff`工具并比较两个文件夹–`$BOOK_HOME/Chapter13`和`$BOOK_HOME/Chapter14`。

# 使用 Spring Cloud Sleuth 和 Zipkin 引入分布式跟踪

从[第 8 章](08.html)、*春云简介*进行总结，参照*春云侦探和 Zipkin 分布式追踪*部分，一个完整工作流的追踪信息称为**追踪**或**追踪****树**和树的子部分，例如基本工作单元，称为**跨度**。跨距可以由形成跟踪树的子跨距组成。Zipkin UI 可以可视化跟踪树及其跨度，如下所示：

![](img/c486eb1c-6ecf-4f66-9783-fdecfe33f7dc.png)

Spring Cloud Sleuth 可以通过 HTTP 同步或使用 RabbitMQ 或 Kafka 等消息代理异步向 Zipkin 发送跟踪信息。为了避免从微服务在 Zipkin 服务器上创建运行时依赖关系，最好使用 RabbitMQ 或 Kafka 异步向 Zipkin 发送跟踪信息。下图说明了这一点：

![](img/0006d41f-9f89-4f39-a1ca-8d3971451602.png)

Zipkin 提供了本机支持，可以将跟踪信息存储在内存中，也可以存储在 Apache Cassandra、Elasticsearch 或 MySQL 中。除此之外，还提供了许多扩展。详见[https://zipkin.apache.org/pages/extensions_choices.html](https://zipkin.apache.org/pages/extensions_choices.html) [。](https://zipkin.apache.org/pages/extensions_choices.html)在本章中，我们将跟踪信息存储在内存中。

# 向源代码添加分布式跟踪

在本节中，我们将学习如何更新源代码，以使用 Spring Cloud Sleuth 和 Zipkin 实现分布式跟踪。这可以通过以下步骤完成：

1.  向构建文件中添加依赖项，以引入 Spring Cloud Sleuth 和向 Zipkin 发送跟踪信息的功能。
2.  为以前没有使用过的项目，即 Spring 云项目`authorization-server`、`eureka-server`和`gateway`向 RabbitMQ 和 Kafka 添加依赖项。
3.  配置微服务以使用 RabbitMQ 或 Kafka 向 Zipkin 发送跟踪信息。
4.  将 Zipkin 服务器添加到 Docker compose 文件。
5.  将`docker-compose-kafka.yml`中的`kafka`弹簧剖面添加到弹簧云项目`authorization-server`、`eureka-server`和`gateway`中。

添加 Zipkin 服务器将使用 Zipkin 项目发布的 Docker Hub 中的 Docker 映像生效。参见[https://hub.docker.com/r/openzipkin/zipkin](https://hub.docker.com/r/openzipkin/zipkin) 了解详情。

Zipkin 本身就是一个 Spring BooT 应用程序，在编写时，在 Apache 软件基金会 To1 T1（Stare T2A.AsSoftware T3）中进行孵化。参见[https://zipkin.apache.org/](https://zipkin.apache.org/) 了解更多信息。

# 添加依赖项以生成文件

为了能够利用 Spring Cloud Sleuth 和向 Zipkin 发送跟踪信息的能力，我们需要向 Gradle 项目构建文件`build.gradle`添加几个依赖项。

这是通过添加以下两行来实现的：

```
implementation('org.springframework.cloud:spring-cloud-starter-sleuth')   implementation('org.springframework.cloud:spring-cloud-starter-zipkin')
```

对于以前没有使用过 RabbitMQ 和 Kafka 的 Gradle 项目，即 Spring 云项目`authorization-server`、`eureka-server`和`gateway`，需要添加以下依赖项：

```
implementation('org.springframework.cloud:spring-cloud-starter-stream-rabbit')
implementation('org.springframework.cloud:spring-cloud-starter-stream-kafka')
```

# 添加 Spring Cloud Sleuth 和 Zipkin 的配置

将使用 Spring Cloud Sleuth 和 Zipkin 的配置添加到公共配置文件`config-repo/application.yml`。在默认配置文件中，指定跟踪信息应使用 RabbitMQ 发送到 Zipkin：

```
spring.zipkin.sender.type: rabbit
```

默认情况下，SpringCloudSleuth 只向 Zipkin 发送 10%的跟踪。为确保将所有跟踪发送到 Zipkin，将在默认配置文件中添加以下属性：

```
spring.sleuth.sampler.probability: 1.0
```

当使用 Kafka 向 Zipkin 发送跟踪时，将使用弹簧配置文件`kafka`。在前面的章节中，`kafka`弹簧配置文件是在特定于复合和核心微服务的配置文件中定义的。在本章中，Spring 云服务还将使用 Kafka 向 Zipkin 发送跟踪信息，`kafka`Spring 配置文件被移动到公共配置文件`config-repo/application.yml`。`kafka`弹簧外形中还添加了以下两个特性：

*   `spring.zipkin.sender.type: kafka`告诉 Spring Cloud 侦探使用卡夫卡将跟踪信息发送给 Zipkin
*   `spring.kafka.bootstrap-servers: kafka:9092`指定在何处查找卡夫卡服务器。

总之，`kafka`弹簧外形如下所示：

```
--- 
spring.profiles: kafka

management.health.rabbit.enabled: false
spring.cloud.stream.defaultBinder: kafka
spring.zipkin.sender.type: kafka
spring.kafka.bootstrap-servers: kafka:9092
```

# 将 Zipkin 添加到 Docker Compose 文件

如前所述，Zipkin 服务器使用 Zipkin 项目发布的已有 Docker 映像`openzipkin/zipkin`添加到 Docker Compose 文件中。在使用 RabbitMQ 的`docker-compose.yml`和`docker-compose-partitions.yml`中，Zipkin 服务器的定义如下：

```
zipkin:
  image: openzipkin/zipkin:2.12.9
  networks:
    - my-network
  environment:
    - RABBIT_ADDRESSES=rabbitmq
    - STORAGE_TYPE=mem
  mem_limit: 512m
  ports:
    - 9411:9411
  depends_on:
    rabbitmq:
      condition: service_healthy
```

让我们解释一下前面的源代码：

*   Docker 映像的版本`openzipkin/zipkin`被指定为版本`2.12.19`。
*   `RABBIT_ADDRESSES=rabbitmq`环境变量用于指定 Zipkin 应使用 RabbitMQ 接收跟踪信息，Zipkin 应使用主机名`rabbitmq`连接到 RabbitMQ。
*   `STORAGE_TYPE=mem`环境变量用于指定 Zipkin 应将所有跟踪信息保存在内存中。
*   Zipkin 的内存限制增加到 512 MB，而所有其他容器的内存限制都是 350 MB。原因是，由于 Zipkin 配置为将所有跟踪信息保留在内存中，因此在一段时间后，它将比其他容器消耗更多内存
*   Zipkin 公开 HTTP 端口`9411`供 web 浏览器访问其 web 用户界面。
*   Docker 将等待启动 Zipkin 服务器，直到 RabbitMQ 服务向 Docker 报告运行正常。

虽然可以将跟踪信息存储在 Zipkin 内存中以供开发和测试活动使用，但 Zipkin 应该配置为在生产环境中的数据库（如 Apache Cassandra、Elasticsearch 或 MySQL）中存储跟踪信息。

在`docker-compose-kafka.yml`中，使用 Kafka 时，Zipkin 服务器的定义如下：

```
zipkin:
  image: openzipkin/zipkin:2.12.9  
  networks: 
    - my-network 
  environment:
    - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    - STORAGE_TYPE=mem 
  mem_limit: 512m
  ports: 
    - 9411:9411 
  depends_on: 
    - kafka
```

让我们详细解释前面的源代码：

*   与 Kafka 一起使用 Zipkin 的配置与之前将 Zipkin 与 RabbitMQ 一起使用时的配置类似。
*   主要区别在于使用了`KAFKA_BOOTSTRAP_SERVERS=kafka:9092`环境变量，该变量用于指定 Zipkin 应使用 Kafka 接收跟踪信息，Zipkin 应使用主机名`kafka`和端口`9092`连接到 Kafka。

在`docker-compose-kafka.yml`中，将`kafka`Spring 配置文件添加到 Spring 云服务`eureka`、`gateway`和`auth-server`：

```
    environment:
      - SPRING_PROFILES_ACTIVE=docker,kafka
```

这就是使用 Spring Cloud Sleuth 和 Zipkin 添加分布式跟踪所需要的，所以让我们在下一节中尝试一下！

# 尝试分布式跟踪

对源代码进行必要的更改后，我们可以尝试分布式跟踪！我们将通过执行以下步骤来实现这一点：

1.  使用 RabbitMQ 作为队列管理器构建、启动和验证系统环境。
2.  发送一个成功的 API 请求，并查看我们可以在 Zipkin 中找到哪些与此 API 请求相关的跟踪信息。
3.  发送一个不成功的 API 请求并查看 Zipkin 中的跟踪信息。
4.  发送触发异步处理的成功 API 请求，并查看其跟踪信息在 Zipkin 中的表示方式。
5.  研究如何监视在 RabbitMQ 中传递给 Zipkin 的跟踪信息。
6.  将队列管理器切换到 Kafka 并重复前面的步骤。

我们将在接下来的章节中详细讨论这些步骤。

# 以 RabbitMQ 作为队列管理器启动系统环境

让我们启动系统景观。使用以下命令生成 Docker 映像：

```
cd $BOOK_HOME/Chapter14
./gradlew build && docker-compose build
```

在 Docker 中启动系统景观，并使用以下命令运行常规测试：

```
./test-em-all.bash start
```

在调用 API 之前，我们需要一个访问令牌。运行以下命令以获取访问令牌：

```
unset ACCESS_TOKEN
ACCESS_TOKEN=$(curl -k https://writer:secret@localhost:8443/oauth/token -d grant_type=password -d username=magnus -d password=password -s | jq -r .access_token)
echo $ACCESS_TOKEN
```

# 发送成功的 API 请求

现在，我们准备向 API 发送一个普通请求。运行以下命令：

```
curl -H "Authorization: Bearer $ACCESS_TOKEN" -k https://localhost:8443/product-composite/2 -w "%{http_code}\n" -o /dev/null -s
```

预期该命令将返回 HTTP 状态代码 success，200。

我们现在可以启动 Zipkin UI，查看哪些跟踪信息已发送到 Zipkin：

1.  在 web 浏览器中打开以下 URL:`http://localhost:9411/zipkin/.`
2.  要查找请求的跟踪信息，请执行以下步骤：
    1.  选择服务名称：网关。
    2.  将排序顺序设置为“最新优先”。
    3.  单击“查找跟踪”按钮。

查找跟踪的响应应如以下屏幕截图所示：

![](img/ee509be8-dcc5-41bb-b758-361379f8fe94.png)

来自前面 API 请求的跟踪信息是列表中的第一个。单击它以查看有关跟踪的详细信息：

![](img/8fa726b9-d1b5-424a-ade5-c5324f925c2c.png)

在详细跟踪信息视图中，我们可以观察到以下情况：

1.  网关服务已收到该请求。
2.  它将请求的处理委托给产品组合服务。
3.  产品组合服务依次向核心服务发送三个并行请求：产品、推荐和评审。
4.  一旦产品组合服务收到来自所有三个核心服务的响应，它就会创建一个组合响应。
5.  复合响应通过网关服务发送回调用方。

在使用 Safari 时，我注意到跟踪树并非总是正确渲染。切换到 Chrome 或 Firefox 解决了这个问题。

如果单击第一个跨距 gateway，我们可以看到更多详细信息：

![](img/f6f693ce-7cea-43ea-ba6c-8faa8db74269.png)

在这里，我们可以看到我们发送的实际请求：product composite/2。例如，在分析需要很长时间才能完成的跟踪时，这非常有价值！

# 发送不成功的 API 请求

让我们看看如果我们发出一个不成功的 API 请求，跟踪信息会是什么样子；例如，搜索不存在的产品：

1.  发送产品 ID`12345`的 API 请求，并验证其是否返回未找到 404 的 HTTP 状态码：

```
curl -H "Authorization: Bearer $ACCESS_TOKEN" -k https://localhost:8443/product-composite/12345 -w "%{http_code}\n" -o /dev/null -s
```

2.  在 Zipkin UI 中，返回搜索页面（使用 web 浏览器中的“后退”按钮）并单击“查找痕迹”按钮。您应该在返回列表的顶部看到失败的请求，红色：

![](img/3b7bf196-16fe-4277-8e51-3f393696278f.png)

3.  单击顶部标记为红色的轨迹：

![](img/4ca53dfa-35ad-4c3c-b50f-8e3a3c357f61.png)

4.  在详细的跟踪视图中，我们可以通过颜色编码看到，当产品组合调用产品服务时，请求出错。单击产品范围以查看出错的详细信息：

![](img/b33855c9-3b3e-4aaf-81ed-8a080c05dec7.png)

在这里，我们可以看到是什么请求导致了错误，product/12345，以及返回的错误代码和原因：404 未找到。这在分析故障的根本原因时非常有用！

# 发送触发异步处理的 API 请求

第三种类型的请求很有趣，可以看到它在 Zipkin UI 中是如何表示的，它是一种请求，其中部分处理是异步完成的。让我们尝试一个删除请求，其中核心服务中的删除过程是异步完成的。`product-composite`服务通过 MessageBroker 向三个核心服务中的每一个发送删除事件，每个核心服务接收删除事件并异步处理。多亏了 SpringCloudSleuth，跟踪信息被添加到发送到 MessageBroker 的事件中，从而形成了删除请求的整个处理过程的一致视图。

运行以下命令删除产品 ID 为`12345`的产品，并验证其是否返回 HTTP 状态码成功，200：

```
curl -X DELETE -H "Authorization: Bearer $ACCESS_TOKEN" -k https://localhost:8443/product-composite/12345 -w "%{http_code}\n" -o /dev/null -s
```

请记住，删除操作是幂等的，也就是说，即使产品不存在，它也会成功！

在 Zipkin UI 中，返回搜索页面（使用 web 浏览器中的“后退”按钮）并单击“查找痕迹”按钮。您应该在返回的列表顶部看到删除请求的跟踪：

![](img/c8304d85-6234-4bf4-9470-e18b2f92a68a.png)

单击第一个跟踪以查看其跟踪信息：

![](img/b06714c3-aec0-4166-a066-2001d3c14c3d.png)

在这里，我们可以看到处理删除请求的跟踪信息：

1.  网关服务已收到该请求。
2.  它将请求的处理委托给产品组合服务。
3.  产品组合服务反过来在 MessageBroker 上发布了三个事件（本例中为 RabbitMQ）。
4.  产品组合服务现在完成，并通过网关服务将成功 HTTP 状态代码 200 返回给调用者。
5.  核心服务、产品、推荐和审阅接收删除事件并开始异步处理它们，即彼此独立。

要查看更多详细信息，请单击产品范围：

![](img/7fd269c2-3bc7-4c83-91cd-6a16c6010757.png)

在这里，我们可以看到产品服务是由从 MessageBroker 发送到其输入通道的事件触发的。

Zipkin 用户界面包含了更多的查找感兴趣的痕迹的功能！
为了更习惯 Zipkin UI，请尝试使用`Annotation Query`参数；例如，使用`http.path=/product-composite/214`或`error=401`搜索特定请求，以查找由于授权失败而失败的请求。注意`Limit`参数，默认设置为`10`；如果没有提出，这可能会隐藏感兴趣的结果。另外，确保`Lookback`参数不会删除感兴趣的痕迹！

# 监视在 RabbitMQ 中传递给 Zipkin 的跟踪信息

要监视通过 RabbitMQ 发送到 Zipkin 的跟踪信息，我们可以使用 RabbitMQ 管理 web UI。在 web 浏览器中打开以下 URL:`http://localhost:15672/#/queues/%2F/zipkin`。如果需要，请使用用户名`guest`和密码`guest`登录。预期网页的外观如下所示：

![](img/0ebbf762-280a-457c-b52e-7344c666c249.png)

在名为`Message Rates`的图中，我们可以看到跟踪消息被发送到 Zipkin，目前平均速率为每秒 1.2 条消息。

通过关闭系统环境，结束使用 RabbitMQ 的分布式跟踪测试。运行以下命令：

```
docker-compose down
```

# 使用 Kafka 作为消息代理

我们还将验证是否可以使用 Kafka 而不是 RabbitMQ 将跟踪信息发送到 Zipkin！

使用以下命令启动系统环境：

```
export COMPOSE_FILE=docker-compose-kafka.yml
./test-em-all.bash start
```

重复我们在前面使用 RabbitMQ 的部分中执行的命令，并验证您在使用 Kafka 时可以在 Zipkin UI 中看到相同的跟踪信息！

Kafka 没有 RabbitMQ 那样的管理 web UI。因此，我们需要运行一些 Kafka 命令，以便能够验证跟踪事件是否确实使用 Kafka 传递到 Zipkin 服务器：

有关在将 Kafka 作为 Docker 容器运行时如何运行 Kafka 命令的概述，请参阅[第 7 章](07.html)*开发反应式微服务中的*使用 Kafka，每个主题*有两个分区。*

1.  首先，列出卡夫卡中可用的主题：

```
docker-compose exec kafka /opt/kafka/bin/kafka-topics.sh --zookeeper zookeeper --list
```

2.  希望找到一个名为`zipkin`的主题：

![](img/8ce689f9-3d7a-49de-b487-817b43554f35.png)

3.  接下来，询问发送到`zipkin`主题的跟踪事件：

```
docker-compose exec kafka /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic zipkin --from-beginning --timeout-ms 1000
```

4.  预计会发生许多类似于以下的事件：

![](img/8fcdde07-be13-497a-8b95-1b56e4fe3a95.png)

跟踪事件的详细信息并不重要。Zipkin 服务器为我们分类，并使信息在 Zipkin UI 中呈现出来。这里重要的一点是，我们可以看到跟踪事件实际上是使用 Kafka 发送到 Zipkin 服务器的。

现在，关闭系统景观并取消设置`COMPOSE_FILE`环境变量：

```
docker-compose down
unset COMPOSE_FILE
```

关于分布式跟踪的这一章到此结束！

# 总结

在本章中，我们学习了如何使用分布式跟踪来理解我们的微服务是如何协作的。我们已经学习了如何使用 SpringCloudSleuth 收集跟踪信息，以及如何使用 Zipkin 存储和可视化跟踪信息。

为了促进运行时组件的解耦，我们学习了如何配置微服务，在使用 RabbitMQ 和 Kafka 作为消息代理的同时，将跟踪信息异步发送到 Zipkin 服务器。我们已经看到，通过向构建文件添加几个依赖项并设置几个配置参数，将 Spring Cloud Sleuth 添加到微服务中会产生怎样的影响。我们还看到了 Zipkin UI 如何使识别复杂工作流的哪一部分导致意外的长响应时间或错误变得非常容易。Zipkin UI 可以可视化同步和异步工作流。

在下一章中，我们将学习容器编排器，特别是 Kubernetes。我们将学习如何使用 Kubernetes 部署和管理微服务，同时改进重要的运行时特性，如可伸缩性、高可用性和恢复能力。

# 问题

1.  使用什么配置参数来控制跟踪信息如何发送到 Zipkin？
2.  `spring.sleuth.sampler.probability`配置参数的用途是什么？
3.  在执行`test-em-all.bash`测试脚本后，如何识别运行时间最长的请求？
4.  我们如何找到被[第 13 章](13.html)*中引入的超时中断的请求，使用 Resilience4j*提高弹性？
5.  当[第 13 章](13.html)*使用 Resilience4j*提高弹性中引入的断路器打开时，API 请求的跟踪是什么样子的？
6.  我们如何定位在未被授权执行请求的调用方上失败的 API？